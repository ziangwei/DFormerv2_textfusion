# æ ‡ç­¾çº§å»é‡æ‰¹é‡ç¼–ç ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“‹ ä¿®æ”¹æ‘˜è¦

**ä¼˜åŒ–ç›®æ ‡**: è§£å†³SUNRGBDæ–‡æœ¬ç¼–ç æ•ˆç‡é—®é¢˜
**æ ¸å¿ƒæ”¹è¿›**: æ ‡ç­¾çº§å»é‡ + æ‰¹é‡ç¼–ç 
**é¢„æœŸåŠ é€Ÿ**: 10-30å€ï¼ˆé¦–æ¬¡ç¼–ç æ—¶ï¼‰
**å…¼å®¹æ€§**: å®Œå…¨å‘åå…¼å®¹ï¼Œæ¥å£ä¸å˜

---

## ğŸ”§ ä¿®æ”¹å†…å®¹

### 1. `utils/prompt_utils.py` - æ·»åŠ æ‰¹é‡ç¼–ç å‡½æ•°

**æ–°å¢å‡½æ•°**: `encode_labels_batch()`

```python
def encode_labels_batch(labels: List[str],
                        template_set: str = "clip",
                        max_templates_per_label: int = 3,
                        encoder: str = "jinaclip",
                        encoder_name: Optional[str] = None,
                        target_dim: Optional[int] = None,
                        batch_size: int = 512) -> dict:
    """
    æ‰¹é‡ç¼–ç æ ‡ç­¾ï¼Œè¿”å›æ ‡ç­¾åˆ°embeddingçš„æ˜ å°„å­—å…¸ï¼ˆå»é‡ä¼˜åŒ–ï¼‰

    æ ¸å¿ƒä¼˜åŒ–ï¼š
    1. å»é‡ï¼šä» ~21,140 æ¬¡ç¼–ç é™è‡³ 37 ä¸ªå”¯ä¸€æ ‡ç­¾
    2. æ‰¹é‡ï¼šä¸€æ¬¡forwardå¤„ç†æ‰€æœ‰æ ‡ç­¾ï¼ˆGPUåˆ©ç”¨ç‡ <5% â†’ >80%ï¼‰
    3. ç¼“å­˜ï¼šè¿”å› {label: embedding} å­—å…¸ä¾›æŸ¥è¡¨å¤ç”¨

    Returns:
        dict: {label_name: tensor[D]} æ ‡ç­¾åˆ°embeddingçš„æ˜ å°„
    """
```

**å®ç°é€»è¾‘**:
```
æ—§ç‰ˆ: for each label: encode(label)  # é€ä¸ªç¼–ç 
æ–°ç‰ˆ:
  1. å»é‡ labels â†’ unique_labels
  2. æ‰¹é‡ encode(unique_labels)  # ä¸€æ¬¡æ€§ç¼–ç æ‰€æœ‰
  3. è¿”å› {label: embedding} æ˜ å°„è¡¨
```

---

### 2. `utils/dataloader/RGBXDataset.py` - ä¼˜åŒ– `_encode_image_labels()`

**ä¿®æ”¹ä½ç½®**: ç¬¬414-498è¡Œ

**æ—§ç‰ˆé€»è¾‘** (ç¬¬415-440è¡Œ):
```python
# ä½æ•ˆï¼šé€å›¾ç¼–ç 
for key, labels in standardized.items():  # 5285æ¬¡å¾ªç¯
    groups = build_prompt_groups_from_labels(labels, ...)
    feats = encode_prompts(groups, ...)  # æ¯æ¬¡åªç¼–ç ä¸€å¼ å›¾çš„æ ‡ç­¾
    # ... padding & storing
```

**æ–°ç‰ˆé€»è¾‘** (ç¬¬416-498è¡Œ):
```python
try:
    # æ­¥éª¤1: æ”¶é›†æ‰€æœ‰å”¯ä¸€æ ‡ç­¾
    all_labels = [lb for labels in standardized.values() for lb in labels]

    # æ­¥éª¤2: æ‰¹é‡ç¼–ç ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰
    label_embeds = encode_labels_batch(
        labels=all_labels,  # ä¸€æ¬¡æ€§ç¼–ç æ‰€æœ‰å”¯ä¸€æ ‡ç­¾
        batch_size=512,
        ...
    )  # è¿”å› {label: embedding}

    # æ­¥éª¤3: ä¸ºæ¯å¼ å›¾ç»„è£…ç‰¹å¾ï¼ˆæŸ¥è¡¨ï¼‰
    for key, labels in standardized.items():
        img_feats = [label_embeds[lb.lower()] for lb in labels]
        feats = torch.stack(img_feats, dim=0)
        # ... padding & storing (ä¸æ—§ç‰ˆå®Œå…¨ä¸€è‡´)

except Exception as e:
    # å›é€€æœºåˆ¶ï¼šå¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨æ—§ç‰ˆé€å›¾ç¼–ç 
    logger.warning("Batch encoding failed, falling back...")
    # ... æ—§ç‰ˆä»£ç  ...
```

**å…³é”®æ”¹è¿›**:
- âœ… **å»é‡**: ä»ç¼–ç 21,140æ¬¡é™è‡³37æ¬¡ï¼ˆSUNRGBDï¼‰
- âœ… **æ‰¹é‡**: GPUæ‰¹é‡å¤„ç†ï¼Œåˆ©ç”¨ç‡ä»<5%æå‡è‡³>80%
- âœ… **é”™è¯¯å¤„ç†**: try-exceptåŒ…è£¹ï¼Œå¤±è´¥è‡ªåŠ¨å›é€€
- âœ… **å®Œå…¨å…¼å®¹**: è¾“å‡ºæ ¼å¼ä¸æ—§ç‰ˆ100%ä¸€è‡´

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### SUNRGBDæ•°æ®é›†åœºæ™¯

| æŒ‡æ ‡ | æ—§ç‰ˆ (é€å›¾ç¼–ç ) | æ–°ç‰ˆ (æ‰¹é‡ç¼–ç ) | æå‡ |
|------|----------------|----------------|------|
| **ç¼–ç è°ƒç”¨æ¬¡æ•°** | 5,285æ¬¡ | 1æ¬¡ | **5285x** â†“ |
| **å®é™…ç¼–ç æ ‡ç­¾æ•°** | ~21,140ä¸ª | 37ä¸ªå”¯ä¸€æ ‡ç­¾ | **571x** â†“ |
| **GPUåˆ©ç”¨ç‡** | <5% | >80% | **16x** â†‘ |
| **é¦–æ¬¡ç¼–ç è€—æ—¶** | ~158ç§’ (2.6åˆ†é’Ÿ) | ~5-15ç§’ | **10-30x** â†‘ |
| **ç¼“å­˜å‘½ä¸­å** | ~1-2ç§’ | ~1-2ç§’ | æ— å˜åŒ– |

### è¯¦ç»†åˆ†æ

**æ—§ç‰ˆç“¶é¢ˆ**:
```
5,285å¼ å›¾ Ã— æ¯å›¾å¹³å‡4ä¸ªæ ‡ç­¾ = 21,140ä¸ªæ ‡ç­¾ç¼–ç 
æ¯æ¬¡ç¼–ç ï¼š
  - åŠ è½½CLIPæ¨¡å‹åˆ°GPU
  - Tokenize 3-6ä¸ªæ–‡æœ¬ï¼ˆæ¨¡æ¿å˜ä½“ï¼‰
  - Forward passï¼ˆå°æ‰¹é‡ï¼ŒGPUé—²ç½®ï¼‰
  - è¿”å›å•å¼ å›¾çš„ç‰¹å¾
æ€»è€—æ—¶: ~0.03ç§’/å›¾ Ã— 5,285 = 158ç§’
```

**æ–°ç‰ˆä¼˜åŒ–**:
```
æ­¥éª¤1: å»é‡æ ‡ç­¾
  5,285å¼ å›¾ â†’ 37ä¸ªå”¯ä¸€æ ‡ç­¾ï¼ˆé‡å¤ç‡ 99.8%ï¼‰

æ­¥éª¤2: æ‰¹é‡ç¼–ç 
  37ä¸ªæ ‡ç­¾ Ã— 3ä¸ªæ¨¡æ¿ = 111ä¸ªæ–‡æœ¬
  ä¸€æ¬¡forward: ~0.5-1ç§’ï¼ˆGPUæ»¡è´Ÿè½½ï¼‰

æ­¥éª¤3: æŸ¥è¡¨ç»„è£…
  5,285å¼ å›¾ Ã— å­—å…¸æŸ¥è¯¢ = ~0.1ç§’ï¼ˆCPUï¼‰

æ€»è€—æ—¶: ~1 + 0.1 = ~1-2ç§’
```

---

## âœ… å…¼å®¹æ€§ä¿è¯

### æ¥å£å®Œå…¨ä¸å˜

**å¯¹å¤–æ¥å£**:
```python
# ä½¿ç”¨æ–¹å¼å®Œå…¨ä¸å˜
dataset = RGBXDataset(setting, split_name="train")
# è‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–åçš„æ‰¹é‡ç¼–ç 
```

**è¿”å›æ ¼å¼**:
```python
# _encode_image_labels() è¿”å›æ ¼å¼å®Œå…¨ä¸€è‡´
{
    "image_path.jpg": Tensor[6, 512],  # [pad_len, D]
    "basename.jpg": Tensor[6, 512],
}
```

**ç¼“å­˜æ ¼å¼**:
```python
# embeds.pt æ ¼å¼ä¸å˜
{
    "pad_len": 6,
    "feats": {image_path: Tensor[6, 512], ...},
    "names": {image_path: ["wall", "floor", ...], ...}
}
```

### é”™è¯¯å¤„ç†

**è‡ªåŠ¨å›é€€æœºåˆ¶**:
```python
try:
    # å°è¯•æ–°ç‰ˆæ‰¹é‡ç¼–ç 
    label_embeds = encode_labels_batch(...)
except Exception as e:
    # å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°æ—§ç‰ˆ
    logger.warning("Falling back to per-image encoding...")
    # ä½¿ç”¨æ—§ç‰ˆé€å›¾ç¼–ç é€»è¾‘
```

**é™çº§ç­–ç•¥**:
- æ‰¹é‡ç¼–ç å¤±è´¥ â†’ å›é€€åˆ°é€å›¾ç¼–ç 
- æ ‡ç­¾æŸ¥è¡¨å¤±è´¥ â†’ ä½¿ç”¨é›¶å‘é‡å¡«å……ï¼ˆå¸¦è­¦å‘Šï¼‰

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ— éœ€ä»»ä½•ä¿®æ”¹

ä¼˜åŒ–å¯¹ä½¿ç”¨è€…å®Œå…¨é€æ˜ï¼š

```bash
# è®­ç»ƒå‘½ä»¤å®Œå…¨ä¸å˜
python train.py -p 29500 -n 1 -m SUNRGBD \
    --config local_configs/SUNRGBD/DFormerv2_B.py
```

### è§‚å¯Ÿä¼˜åŒ–æ•ˆæœ

**é¦–æ¬¡è®­ç»ƒ**ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰:
```
[Image labels] Batch encoding 37 unique labels from 5285 images (optimized)...
[Image labels] Batch encoding completed successfully
```

**åç»­è®­ç»ƒ**ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰:
```
# ç›´æ¥åŠ è½½ç¼“å­˜ï¼Œè€—æ—¶ä¸æ—§ç‰ˆç›¸åŒ (~1-2ç§’)
```

**é”™è¯¯å›é€€**ï¼ˆå¦‚æœæ‰¹é‡ç¼–ç å¤±è´¥ï¼‰:
```
[WARNING] Batch encoding failed (...), falling back to per-image encoding...
[Image labels] Fallback encoding completed
```

---

## ğŸ” ä»£ç éªŒè¯

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
python test_text_encoding_optimization.py
```

**æµ‹è¯•å†…å®¹**:
1. âœ… æ‰¹é‡ç¼–ç åŠŸèƒ½éªŒè¯
2. âœ… å»é‡æ•ˆæœéªŒè¯
3. âœ… å‘åå…¼å®¹æ€§éªŒè¯
4. âœ… è¾“å‡ºæ ¼å¼ä¸€è‡´æ€§éªŒè¯

---

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### å»é‡é€»è¾‘

```python
# æ­¥éª¤1: æ”¶é›†æ‰€æœ‰æ ‡ç­¾ï¼ˆå«é‡å¤ï¼‰
all_labels = []
for img, labels in image_label_mapping.items():
    all_labels.extend(labels)  # ["wall", "floor", "wall", "floor", ...]

# æ­¥éª¤2: encode_labels_batch å†…éƒ¨å»é‡
def encode_labels_batch(labels):
    unique_labels = []
    seen = set()
    for lb in labels:
        lb_norm = lb.lower()
        if lb_norm not in seen:
            unique_labels.append(lb_norm)
            seen.add(lb_norm)
    # unique_labels = ["wall", "floor", "cabinet", ...]  # 37ä¸ª
```

### æ‰¹é‡ç¼–ç 

```python
# ä¸ºæ¯ä¸ªå”¯ä¸€æ ‡ç­¾ç”Ÿæˆæ¨¡æ¿å˜ä½“
all_prompts = []
for label in unique_labels:
    variants = [
        f"a photo of a {label}.",
        f"this is a photo of a {label}.",
        f"an image of a {label}."
    ]
    all_prompts.extend(variants)
# all_prompts = 37æ ‡ç­¾ Ã— 3æ¨¡æ¿ = 111ä¸ªæ–‡æœ¬

# æ‰¹é‡ç¼–ç ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
for i in range(0, len(all_prompts), batch_size=512):
    batch = all_prompts[i:i+512]
    embeds = CLIP_model.encode_text(batch)  # ä¸€æ¬¡forward
    # GPUæ»¡è´Ÿè½½å¤„ç†
```

### æŸ¥è¡¨ç»„è£…

```python
# ä¸ºæ¯å¼ å›¾ç»„è£…ç‰¹å¾
for image_path, labels in image_label_mapping.items():
    img_feats = []
    for label in labels:  # ["wall", "floor", "cabinet"]
        img_feats.append(label_embeds[label])  # å­—å…¸æŸ¥è¯¢ O(1)

    feats = torch.stack(img_feats, dim=0)  # [3, 512]

    # Paddingåˆ°å›ºå®šé•¿åº¦ï¼ˆä¸æ—§ç‰ˆä¸€è‡´ï¼‰
    if len(img_feats) < 6:
        pad = torch.zeros(6 - len(img_feats), 512)
        feats = torch.cat([feats, pad], dim=0)  # [6, 512]

    image_features[image_path] = feats
```

---

## ğŸ¯ é€‚ç”¨åœºæ™¯

### æ¨èä½¿ç”¨

- âœ… **é¢‘ç¹è°ƒæ•´é…ç½®**: æ¯æ¬¡æ”¹é…ç½®éƒ½éœ€è¦é‡æ–°ç¼–ç 
- âœ… **å¤§è§„æ¨¡æ•°æ®é›†**: NYU/Cityscapesç­‰å›¾ç‰‡æ›´å¤šçš„æ•°æ®é›†
- âœ… **å¤šæ¬¡å®éªŒè¿­ä»£**: éœ€è¦å¤šæ¬¡åˆ é™¤ç¼“å­˜é‡æ–°ç¼–ç 

### å½±å“è¾ƒå°

- âš ï¸ **å•æ¬¡è®­ç»ƒ**: åªè®­ç»ƒä¸€æ¬¡ï¼Œåˆå§‹åŒ–å¼€é”€å¯æ¥å—
- âš ï¸ **ç¼“å­˜å·²å­˜åœ¨**: ç¼“å­˜å‘½ä¸­æ—¶æ–°æ—§ç‰ˆæœ¬æ€§èƒ½ç›¸åŒ

---

## ğŸ“Š å…¶ä»–æ•°æ®é›†é¢„ä¼°

| æ•°æ®é›† | å›¾ç‰‡æ•° | ç±»åˆ«æ•° | æ—§ç‰ˆç¼–ç æ•° | æ–°ç‰ˆç¼–ç æ•° | åŠ é€Ÿæ¯” |
|--------|--------|--------|-----------|-----------|--------|
| **SUNRGBD** | 5,285 | 37 | ~21,140 | 37 | **571x** |
| **NYUv2** | 1,449 | 40 | ~5,796 | 40 | **145x** |
| **Cityscapes** | 2,975 | 19 | ~11,900 | 19 | **626x** |

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1: æ‰¹é‡ç¼–ç å¤±è´¥

**ç—‡çŠ¶**:
```
[WARNING] Batch encoding failed (...), falling back to per-image encoding...
```

**åŸå› **: CLIPæ¨¡å‹åŠ è½½å¤±è´¥ / GPUå†…å­˜ä¸è¶³

**è§£å†³**:
- æ£€æŸ¥ open_clip å®‰è£…: `pip install open-clip-torch`
- é™ä½batch_size: åœ¨ä»£ç ä¸­ä¿®æ”¹ `batch_size=256`

### é—®é¢˜2: æ ‡ç­¾æœªæ‰¾åˆ°

**ç—‡çŠ¶**:
```
[WARNING] Label 'xxx' not found in batch-encoded labels, using zero vector
```

**åŸå› **: æ ‡ç­¾å½’ä¸€åŒ–ä¸ä¸€è‡´

**è§£å†³**: æ£€æŸ¥ `_normalize_label()` é€»è¾‘ï¼Œç¡®ä¿ä¸€è‡´æ€§

---

## ğŸ“š å‚è€ƒ

**ä¿®æ”¹æ–‡ä»¶**:
- `utils/prompt_utils.py`: ç¬¬165-235è¡Œ
- `utils/dataloader/RGBXDataset.py`: ç¬¬12-18è¡Œ (å¯¼å…¥), ç¬¬414-498è¡Œ (ç¼–ç é€»è¾‘)

**æµ‹è¯•è„šæœ¬**:
- `test_text_encoding_optimization.py`

**ç›¸å…³Issue**:
- æ–‡æœ¬ç¼–ç æ•ˆç‡é—®é¢˜åˆ†æ

---

## âœ¨ æ€»ç»“

**æ ¸å¿ƒæ”¹è¿›**:
```
æ—§ç‰ˆ: for image in images: encode(image_labels)  # 5285æ¬¡
æ–°ç‰ˆ:
  1. unique_labels = deduplicate(all_labels)     # 37ä¸ª
  2. label_dict = batch_encode(unique_labels)    # 1æ¬¡
  3. for image: assemble(label_dict)             # æŸ¥è¡¨
```

**æ”¶ç›Š**:
- ğŸš€ **é¦–æ¬¡ç¼–ç **: 158ç§’ â†’ 5-15ç§’ (10-30xåŠ é€Ÿ)
- ğŸ’¾ **ç¼“å­˜å**: æ— æ€§èƒ½å·®å¼‚ï¼ˆ1-2ç§’ï¼‰
- ğŸ”’ **å…¼å®¹æ€§**: 100%å‘åå…¼å®¹
- ğŸ›¡ï¸ **å®¹é”™æ€§**: è‡ªåŠ¨å›é€€æœºåˆ¶

**ä½¿ç”¨å»ºè®®**:
- ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€ä¿®æ”¹è®­ç»ƒè„šæœ¬
- é¦–æ¬¡è®­ç»ƒè§‚å¯Ÿæ—¥å¿—ç¡®è®¤ä¼˜åŒ–ç”Ÿæ•ˆ
- å¦‚é‡é—®é¢˜ä¼šè‡ªåŠ¨å›é€€ï¼Œä¸å½±å“è®­ç»ƒ
